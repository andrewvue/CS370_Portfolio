{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 1.6780 - accuracy: 0.4026 - val_loss: 1.4297 - val_accuracy: 0.4947\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 56s 1ms/step - loss: 1.3453 - accuracy: 0.5253 - val_loss: 1.2179 - val_accuracy: 0.5810\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 1.2143 - accuracy: 0.5748 - val_loss: 1.2343 - val_accuracy: 0.5696\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 1.1289 - accuracy: 0.6022 - val_loss: 1.1171 - val_accuracy: 0.6187\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 1.0492 - accuracy: 0.6333 - val_loss: 1.1009 - val_accuracy: 0.6217\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.9968 - accuracy: 0.6526 - val_loss: 1.1659 - val_accuracy: 0.6065\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.9427 - accuracy: 0.6730 - val_loss: 1.2468 - val_accuracy: 0.5895\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.8985 - accuracy: 0.6858 - val_loss: 1.0458 - val_accuracy: 0.6456\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.8573 - accuracy: 0.7014 - val_loss: 1.0059 - val_accuracy: 0.6595\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.8155 - accuracy: 0.7155 - val_loss: 1.0085 - val_accuracy: 0.6639\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.7815 - accuracy: 0.7293 - val_loss: 0.9818 - val_accuracy: 0.6697\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 76s 2ms/step - loss: 0.7408 - accuracy: 0.7434 - val_loss: 1.0176 - val_accuracy: 0.6638\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 106s 3ms/step - loss: 0.7129 - accuracy: 0.7547 - val_loss: 1.0148 - val_accuracy: 0.6699\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 107s 3ms/step - loss: 0.6825 - accuracy: 0.7652 - val_loss: 1.0153 - val_accuracy: 0.6699\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 107s 3ms/step - loss: 0.6596 - accuracy: 0.7709 - val_loss: 1.1070 - val_accuracy: 0.6613\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 108s 3ms/step - loss: 0.6321 - accuracy: 0.7814 - val_loss: 1.0158 - val_accuracy: 0.6710\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 108s 3ms/step - loss: 0.6106 - accuracy: 0.7903 - val_loss: 1.0299 - val_accuracy: 0.6745\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 104s 3ms/step - loss: 0.5883 - accuracy: 0.7964 - val_loss: 1.0114 - val_accuracy: 0.6840\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 106s 3ms/step - loss: 0.5629 - accuracy: 0.8059 - val_loss: 1.0243 - val_accuracy: 0.6825\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 107s 3ms/step - loss: 0.5468 - accuracy: 0.8122 - val_loss: 1.0295 - val_accuracy: 0.6768\n",
      "10000/10000 [==============================] - 11s 1ms/step\n",
      "Test score: 1.0374875438690185\n",
      "Test accuracy: 0.6718000173568726\n",
      "Augmenting training set images...\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "#load dataset\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# float and normalization\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "#And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "NUM_TO_AUGMENT=5\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# augumenting\n",
    "print(\"Augmenting training set images...\")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "rotation_range=40,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest')\n",
    "\n",
    "\n",
    "xtas, ytas = [], []\n",
    "for i in range(X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "x = X_train[i] # (3, 32, 32)\n",
    "x = x.reshape((1,) + x.shape) # (1, 3, 32, 32)\n",
    "for x_aug in datagen.flow(x, batch_size=1,\n",
    "save_to_dir='preview', save_prefix='cifar', save_format='jpeg'):\n",
    "    if num_aug >= NUM_TO_AUGMENT:\n",
    "        break\n",
    "xtas.append(x_aug[0])\n",
    "num_aug += 1\n",
    "\n",
    "\n",
    "#fit the dataget\n",
    "datagen.fit(X_train)\n",
    "# train\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE), samples_per_epoch=X_train.shape[0],\n",
    "epochs=NB_EPOCH, verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown analysis:\n",
    "The algorithm we used here to review animals and non-human images only yielded a Test accuracy: 0.6718000173568726 equating to about 67% accuracy. This is not a high enough accuracy rating to use on identifying humans. This is a major concern because we also see bias in AI programs in the readings we covered this week in class.\n",
    "\n",
    "The of using facial recognition technology is a contentious topic that has sides arguing for and against it on ethical grounds. What I found most interesting during my research about the ethicacy of using facial recognition software was the healthcare sector. It is common knowledge that the healthcare field is very guarded when it comes to patient information and HIPAA regulations to keep patient data private. There have been facial recognition technology that are used in health care settings to \"identify and monitor patients as well as to diagnose genetic, medical, and behavioral conditions\" (Martinez-Martin). These applications sound promising, but there is the issue of patient privacy and data protection. Martinez-Martin discusses many important ethical concerns like informed consent, and bias. The issue surrounding informed consent is that \"informed consent will need to be obtained not only for collecting and storing patients’ images but also for the specific purposes for which those images might be analyzed by FRT systems\"(Martinez-Martin). This means that any and all data must be reported and have a signed consent form from and by the patient. \n",
    "\n",
    "Outside of healthcare facial recognition technology (FRT) is used by both gevernment agencies and commercial organizations and this is a concern because not many countries have common laws to regulate the use of FRT. Law enforcement's use of FRT is also a concern because \"such usage is not disclosed, and people are not aware that they are under state surveillance. The use of FRT by law enforcement has been marked by criticism of bias, discrimination, and lack of transparency\"(Sarabdeen). With the accuracy of only 67% in our model we used to identify animals --not specific individuals within a species-- I don't believe that it is ethical to use facial recognition to identify a potential suspect. It is difficult to trust a model that is only 67% accurate while using photos or videos that are low resolution or blurry to identify human face that have subtle differences in features and skin tones.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "Martinez-Martin, N. JD. PHD. (Feb 2019). What Are Important Ethical Implications of Using Facial Recognition Technology in Health Care? Retrieved from: https://journalofethics.ama-assn.org/article/what-are-important-ethical-implications-using-facial-recognition-technology-health-care/2019-02\n",
    "Sarabdeen, J. (Mar 2022). Protection of the rights of the individual when using facial recognition technology. Retrieved from: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8927940/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
